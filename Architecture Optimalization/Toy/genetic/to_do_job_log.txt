TODO: tpr=0.5 -> fpr as a metric
    - Should there be a choice between this and auc, or should I try to combine them.
    - Actually, why not F-score? It seems to make more sense, as it looks at tpr=0.5, but also looks at fpr, tnr, fnr.

TODO: Momentum as a parameter (READ: hw they behave/conserve in keras with one-by-one epoch calls)
    - Not using, one-by-one epoch calls anymore, due to learning decay as parameter.
    - Since, different opt algorithms have different key-words for momentum (ex. beta_1, beta_2, momentum),
    how should I handle it?

22/06: Learning decay as a parameter:
    - Used Learning rate scheduler: still needs to change some it in __mutate in __Mutator.

TODO: Check the size of the training dataset: https://github.com/36000/cnn_colorflow/blob/master/lcurve.py
    - Need to clone from John.

22/06: Create log file support, instead of printing to console:
    - Done, prints to do bottom of the file.

22/06: No Two max_outs/dropouts in a row:
    - Done, however without possibility of different configs (ex. always two convs in a row, before maxout).

05/07: Use weights of the old network, while creating a new one.
    - 23/06 - add layer - Testing how different layers behave.
    - 28/06 - add layer - First approach, by creating three models, and then merging them.
    - 29/06 - add layer - Deleted first approach.
                            New Approach:
                                1. Create a new model.
                                2. Populate it with copies of old model.
                                3. Set weights to ones from last model + new weights for a new layer.
    - 01/07 - rmv layer - Added a function to remove a layer. Fails, if the layer is first one, or last one.
                            That's not the case in this research though. (First layer is always Activation,
                            last one is Dense w/ 2 neurons).
    - 02/07 - add layer - Implemented into mutating.
                            Fixed a bug when a Conv layer is added right before MaxOut before Flatten.
                            Easy fix though, can be done more efficiently when copying weights.
    - 03/07 - bth fn's  - Implemented remove into mutating.
                            Changed __init__ of network, so that it's easier to make new mutation combinations.
                            Made a function to find a weight index of first Dense layer.
    - 04/07 - bth fn's  - Implemented a function to copy weights from a middle of next dense layer.
    - 05/07 - bth fn's  - Fixed minor bugs, which resulted in incorrect shape.

02-05/07: Make it Maxout safe, when adding new layer. AKA implement limit so that maxpool cannot be added if previous/next layer is maxpool:
    - Fixed during problem above.

04-06/07: Bug. Sometimes training pops out NaNs. Understand why, fix. It's not optimizer, unless there's something wrong with SGD/lr combination.
    Nets:
        1:
            architecture: [((3, 3), 8), 128, 64]
            optimizer   : Adam
            activation  : relu
            callbacks   : EarlyStopping/default
        2:
            architecture: [((7, 7), 16), ((5, 5), 8), 'max', 32, 32, 'drop0.30']
            optimizer   : Adam
            activation  : relu
            callbacks   : EarlyStopping/default
        3:
            architecture: [((5, 5), 8), 'max', ((5, 5), 8), 'max', 64, 'drop0.30']
            optimizer   : Adam
            activation  : relu
            callbacks   : EarlyStopping/default
    Solved.

    Note for future:
        Basically using relu with cross_entropy doesn't work, since 0 is not in domain of cross_entropy, but in range of relu.
        Thus, even though the last activation was tanh, the problem was 0, appearing sometimes in the range of nn(since 0 -> 0 in tanh).
        Use SIGMOID whenever possible as last activation of nn, whenever possible.

TODO: Bug. Nan in loss. Now in middle of the epoch. Maybe something with divergent optimizer.
    Nets:
        1:
            architecture: [((3, 3), 16), 64, 64, 'drop0.70']
            optimizer   : Nadam, 0.001
            activation  : relu
            callbacks   : EarlyStopping/default

17/07: Investigate why dropout at the end of arch is legal. It's shouldn't be.
    - Done, added 'or j == len(architecture) - 1' in __init__ of network. Also added a test, in the test_network.

17/07: Make probability distributions for different choices in __mutate.
    - Done. Used numpy.random instead of random.

TODO: Make different add-ons (such as combination of conv-conv-conv-max)
    - Basically make a function which uses a insert_layer helper method, on a random index
        (ideally with a req. that's it's after maxout).
    - Good idea to create a file called helpers_mutate.

TODO: Limit depth/number of weights.

TODO: To prevent overfitting. Save weights before training, then compare scores after fitting. If it's worse, keep the weights.
    - Should it be done in score or in fit?

TODO: Split helper methods based on what they are helping with. Maybe even make a backend folder.
